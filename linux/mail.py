import imaplib
import email
from email.header import decode_header
import html2text
import telegram
import os
import asyncio
import re
import chardet
from dotenv import load_dotenv
from email.utils import parseaddr
from md2tgmd import escape
import logging
from tencentcloud.common import credential
from tencentcloud.common.profile.client_profile import ClientProfile
from tencentcloud.common.profile.http_profile import HttpProfile
from tencentcloud.tmt.v20180321 import tmt_client, models
import fitz

load_dotenv()

# é…ç½®ä¿¡æ¯
IMAP_SERVER = os.getenv("IMAP_SERVER")
EMAIL_ADDRESS = os.getenv("EMAIL_USER")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_API_KEY")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
MAX_MESSAGE_LENGTH = 3800  # ä¿ç•™å®‰å…¨ä½™é‡
DEBUG_MODE = os.getenv("DEBUG_MODE", "false").lower() == "true"

# è…¾è®¯ç¿»è¯‘é…ç½®
TENCENTCLOUD_SECRET_ID = os.getenv("TENCENTCLOUD_SECRET_ID")
TENCENTCLOUD_SECRET_KEY = os.getenv("TENCENTCLOUD_SECRET_KEY")
TENCENT_REGION = os.getenv("TENCENT_REGION", "na-siliconvalley")
ENABLE_TRANSLATION = os.getenv("ENABLE_TRANSLATION", "true").lower() == "true"

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO if DEBUG_MODE else logging.WARNING)
logger = logging.getLogger(__name__)

def remove_html_tags(text):
    """ç§»é™¤HTMLæ ‡ç­¾"""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def translate_content_sync(text):
    """åŒæ­¥ç¿»è¯‘æ–‡æœ¬ä¸ºä¸­æ–‡ï¼Œæ”¯æŒé•¿æ–‡æœ¬åˆ†æ®µç¿»è¯‘"""
    if not text or not ENABLE_TRANSLATION:
        return text
    
    if not TENCENTCLOUD_SECRET_ID or not TENCENTCLOUD_SECRET_KEY:
        logger.warning("ç¼ºå°‘è…¾è®¯äº‘ç¿»è¯‘å¯†é’¥ï¼Œè·³è¿‡ç¿»è¯‘")
        return text
    
    try:
        cred = credential.Credential(TENCENTCLOUD_SECRET_ID, TENCENTCLOUD_SECRET_KEY)
        http_profile = HttpProfile(endpoint="tmt.tencentcloudapi.com")
        client_profile = ClientProfile(httpProfile=http_profile)
        client = tmt_client.TmtClient(cred, TENCENT_REGION, client_profile)
        
        cleaned_text = remove_html_tags(text)
        
        # æ£€æŸ¥é•¿åº¦ï¼Œå¦‚æœè¶…è¿‡é™åˆ¶åˆ™åˆ†æ®µç¿»è¯‘
        MAX_BYTES = 1900  # ä¿ç•™ä¸€äº›ä½™é‡
        text_bytes = cleaned_text.encode('utf-8')
        
        if len(text_bytes) <= MAX_BYTES:
            # çŸ­æ–‡æœ¬ç›´æ¥ç¿»è¯‘
            req = models.TextTranslateRequest()
            req.SourceText = cleaned_text
            req.Source = "auto"
            req.Target = "zh"
            req.ProjectId = 0
            resp = client.TextTranslate(req)
            return resp.TargetText
        else:
            # é•¿æ–‡æœ¬åˆ†æ®µç¿»è¯‘
            logger.info("æ£€æµ‹åˆ°é•¿æ–‡æœ¬ï¼Œå¼€å§‹åˆ†æ®µç¿»è¯‘...")
            segments = []
            current_segment = ""
            
            # æŒ‰æ®µè½åˆ†å‰²
            paragraphs = [p for p in cleaned_text.split('\n\n') if p.strip()]
            
            for para in paragraphs:
                para_bytes = para.encode('utf-8')
                new_segment = current_segment + ("\n\n" + para if current_segment else para)
                new_segment_bytes = new_segment.encode('utf-8')
                
                if len(new_segment_bytes) > MAX_BYTES:
                    # å½“å‰æ®µè½ä¼šè¶…å‡ºé™åˆ¶ï¼Œå…ˆç¿»è¯‘å·²ç§¯ç´¯çš„å†…å®¹
                    if current_segment:
                        req = models.TextTranslateRequest()
                        req.SourceText = current_segment
                        req.Source = "auto"
                        req.Target = "zh"
                        req.ProjectId = 0
                        resp = client.TextTranslate(req)
                        segments.append(resp.TargetText)
                    
                    # å¦‚æœå•ä¸ªæ®µè½å°±è¶…è¿‡é™åˆ¶ï¼Œå•ç‹¬å¤„ç†
                    if len(para_bytes) > MAX_BYTES:
                        # æŒ‰å¥å­åˆ†å‰²å¤§æ®µè½
                        sentences = re.split(r'[ã€‚.!?ï¼Ÿ]\s*', para)
                        temp_segment = ""
                        for sentence in sentences:
                            if not sentence.strip():
                                continue
                            sentence_with_punct = sentence + "ã€‚"
                            temp_bytes = (temp_segment + sentence_with_punct).encode('utf-8')
                            
                            if len(temp_bytes) > MAX_BYTES and temp_segment:
                                req = models.TextTranslateRequest()
                                req.SourceText = temp_segment
                                req.Source = "auto"
                                req.Target = "zh"
                                req.ProjectId = 0
                                resp = client.TextTranslate(req)
                                segments.append(resp.TargetText)
                                temp_segment = sentence_with_punct
                            else:
                                temp_segment += sentence_with_punct
                        
                        if temp_segment:
                            current_segment = temp_segment
                        else:
                            current_segment = ""
                    else:
                        current_segment = para
                else:
                    current_segment = new_segment
            
            # ç¿»è¯‘æœ€åä¸€æ®µ
            if current_segment:
                req = models.TextTranslateRequest()
                req.SourceText = current_segment
                req.Source = "auto"
                req.Target = "zh"
                req.ProjectId = 0
                resp = client.TextTranslate(req)
                segments.append(resp.TargetText)
            
            return "\n\n".join(segments)
            
    except Exception as e:
        logger.error(f"ç¿»è¯‘å¤±è´¥: {e}")
        return text

async def translate_content_async(text):
    """å¼‚æ­¥ç¿»è¯‘æ–‡æœ¬ä¸ºä¸­æ–‡"""
    loop = asyncio.get_running_loop()
    try:
        return await loop.run_in_executor(None, translate_content_sync, text)
    except Exception as e:
        logger.error(f"å¼‚æ­¥ç¿»è¯‘å¤±è´¥: {e}")
        return text

def is_mainly_chinese(text):
    """æ£€æµ‹æ–‡æœ¬æ˜¯å¦ä¸»è¦æ˜¯ä¸­æ–‡"""
    if not text:
        return True
    
    # è®¡ç®—ä¸­æ–‡å­—ç¬¦çš„æ¯”ä¾‹
    chinese_pattern = re.compile(r'[\u4e00-\u9fff]')
    chinese_chars = len(chinese_pattern.findall(text))
    total_chars = len(text)
    
    # é¿å…é™¤é›¶é”™è¯¯
    if total_chars == 0:
        return True
    
    # å¦‚æœä¸­æ–‡å­—ç¬¦è¶…è¿‡10%çš„æ¯”ä¾‹ï¼Œåˆ™æ— éœ€ç¿»è¯‘
    return (chinese_chars / total_chars) > 0.1

class EmailDecoder:
    @staticmethod
    def decode_email_header(header):
        """æ™ºèƒ½è§£ç é‚®ä»¶å¤´"""
        if not header:
            return ""
        try:
            decoded = decode_header(header)
            return ''.join([
                t[0].decode(t[1] or 'utf-8', errors='ignore') 
                if isinstance(t[0], bytes) 
                else str(t[0])
                for t in decoded
            ])
        except Exception as e:
            logger.error(f"Header decode error: {e}")
            return str(header)

    @staticmethod
    def detect_encoding(content):
        """ç¼–ç æ£€æµ‹ä¼˜åŒ–"""
        try:
            result = chardet.detect(content)
            if result['confidence'] > 0.7:
                return result['encoding']
            return 'gb18030' if b'\x80' in content[:100] else 'utf-8'
        except Exception as e:
            logger.error(f"Encoding detection error: {e}")
            return 'gb18030'

class ContentProcessor:
    @staticmethod
    def normalize_newlines(text):
        """ç»Ÿä¸€æ¢è¡Œç¬¦å¹¶åˆå¹¶ç©ºè¡Œ"""
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        return re.sub(r'\n{3,}', '\n\n', text)
    
    # è½¬ä¹‰åæ¸…ç†è¿ç»­ç©ºè¡Œï¼Œæœ€å¤šä¿ç•™ä¸€ä¸ªç©ºè¡Œ
    @staticmethod
    def collapse_empty_lines(text):
        """æ¸…ç†è¿ç»­ç©ºè¡Œï¼Œæœ€å¤šä¿ç•™ä¸€ä¸ªç©ºè¡Œ"""
        text = re.sub(r'\n{3,}', '\n\n', text)
        text = re.sub(r'^\n+', '', text)
        text = re.sub(r'\n+$', '', text)
        return text
    
    @staticmethod
    def clean_text(text):
        """ç»ˆææ–‡æœ¬æ¸…æ´—"""
        text = text.replace('|', '')
        text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', text)
        text = ContentProcessor.normalize_newlines(text)
        text = '\n'.join(line.strip() for line in text.split('\n'))
        text = re.sub(r'<[^>]+>', '', text)
        return text.strip()

    @staticmethod
    def extract_urls(html):
        """
        æ™ºèƒ½é“¾æ¥è¿‡æ»¤ï¼Œæ’é™¤å›¾ç‰‡ã€è§†é¢‘ã€CSSã€å­—ä½“ã€APIç­‰èµ„æºé“¾æ¥ï¼Œåªè¿”å›ä¸»è¦å†…å®¹ç›¸å…³é¡µé¢é“¾æ¥ã€‚
        æœ€å¤šè¿”å›3ä¸ªæœ‰æ•ˆé“¾æ¥ã€‚
        """
        url_pattern = re.compile(r'(https?://[^\s>"\'{}|\\^`]+)', re.IGNORECASE)
        urls = []
        seen = set()
        exclude_domains = {
            'w3.org', 'schema.org', 'example.com', 'mozilla.org',
            'fonts.googleapis.com', 'googleapis.com'
        }
        # å›¾ç‰‡å’Œè§†é¢‘æ‰©å±•å
        media_extensions = {
            '.jpeg', '.jpg', '.png', '.gif', '.bmp', '.webp', '.svg', '.tiff', '.raw',
            '.mp4', '.mov', '.avi', '.mkv', '.flv', '.webm', '.wmv', '.mpeg', '.mpg', '.3gp', '.m4v', '.ts'
        }
        # å›¾ç‰‡å…³é”®å­—
        media_keywords = {
            '/thumb/', '/image/', '/img/', '/cover/', '/poster/', '/gallery/',
            'picture', 'photo', 'snapshot', 'preview', 'thumbnail'
        }
        # èµ„æºæ–‡ä»¶å…³é”®å­—
        resource_keywords = [
            '/css', '/js', '/font', '/api', '/assets', 'static.', 'cdn.',
            '.css', '.js', '.woff', '.ttf', '.svg'
        ]

        for match in url_pattern.finditer(html):
            raw_url = match.group(1)
            # æ¸…ç†å¯èƒ½æ®‹ç•™çš„ç‰¹æ®Šå­—ç¬¦
            clean_url = re.sub(r'[{}|\\)(<>`]', '', raw_url.split('"')[0])
            # åŸºæœ¬é•¿åº¦è¿‡æ»¤
            if not (10 < len(clean_url) <= 100):
                continue
            # æ’é™¤ç‰¹å®šåŸŸå
            if any(domain in clean_url for domain in exclude_domains):
                continue
            # æ’é™¤å†…è”å›¾ç‰‡
            if clean_url.startswith('data:image/'):
                continue
            # æ’é™¤å›¾ç‰‡å’Œè§†é¢‘æ‰©å±•å
            if any(ext in clean_url.lower() for ext in media_extensions):
                continue
            # æ’é™¤å›¾ç‰‡/è§†é¢‘å…³é”®å­—
            lower_url = clean_url.lower()
            if any(kw in lower_url for kw in media_keywords):
                continue
            # æ’é™¤èµ„æºæ–‡ä»¶
            if any(kw in lower_url for kw in resource_keywords):
                continue
            # æ’é™¤CDNå’Œé™æ€èµ„æº
            if '/cdn/' in lower_url or '/static/' in lower_url or '/assets/' in lower_url:
                continue
            # ç¡®ä¿URLæœ‰è·¯å¾„éƒ¨åˆ†ï¼ˆè‡³å°‘3ä¸ªæ–œæ ï¼Œæ’é™¤çº¯åŸŸåï¼‰
            if clean_url.count('/') < 3:
                continue
            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if clean_url not in seen:
                seen.add(clean_url)
                urls.append(clean_url)
        return urls[:3]  # æœ€å¤šè¿”å›3ä¸ªé“¾æ¥

    @staticmethod
    def convert_html_to_text(html_bytes):
        """HTMLè½¬æ¢å¼ºåŒ–"""
        try:
            encoding = EmailDecoder.detect_encoding(html_bytes)
            html = html_bytes.decode(encoding, errors='replace')
            
            converter = html2text.HTML2Text()
            converter.body_width = 0
            converter.ignore_links = True
            converter.ignore_images = True
            converter.ignore_emphasis = True
            
            text = converter.handle(html)
            text = ContentProcessor.clean_text(text)
            
            urls = ContentProcessor.extract_urls(html)
            
            final_text = text
            if urls:
                final_text += "\n\nç›¸å…³é“¾æ¥ï¼š\n" + "\n".join(urls)
                
            return ContentProcessor.normalize_newlines(final_text)
            
        except Exception as e:
            logger.error(f"HTMLå¤„ç†å¤±è´¥: {e}")
            return "âš ï¸ å†…å®¹è§£æå¼‚å¸¸"
        
def format_boc_bill_data(pdf_text):
    """æ ¼å¼åŒ–ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡è´¦å• - ä¿®å¤ç‰ˆ"""
    try:
        lines = pdf_text.split('\n')
        formatted_lines = []
        
        # è´¦å•å…³é”®ä¿¡æ¯
        bill_info = {
            'åˆ°æœŸè¿˜æ¬¾æ—¥': '',
            'è´¦å•æ—¥': '',
            'æœ¬æœŸäººæ°‘å¸æ¬ æ¬¾æ€»è®¡': '',
            'æœ¬æœŸæœ€å°è¿˜æ¬¾é¢': '',
            'å¡å·': ''
        }
        
        transactions = []
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æ£€æµ‹ç« èŠ‚å˜åŒ–
            if 'è´¦å•ä¿¡æ¯æ€»è§ˆ' in line or 'Account Summary' in line:
                current_section = 'summary'
                continue
            elif 'äººæ°‘å¸äº¤æ˜“æ˜ç»†' in line or 'RMB Transaction Detailed List' in line:
                current_section = 'transactions'
                continue
            elif 'å¡å·' in line and 'æœ¬æœŸåº”è¿˜æ¬¾é¢' in line:
                current_section = 'card_details'
                continue
            
            # æå–è´¦å•æ‘˜è¦ä¿¡æ¯
            if current_section == 'summary':
                if 'åˆ°æœŸè¿˜æ¬¾æ—¥' in line:
                    # æŸ¥æ‰¾æ—¥æœŸæ ¼å¼
                    date_match = re.search(r'(\d{4}-\d{2}-\d{2})', line)
                    if date_match:
                        bill_info['åˆ°æœŸè¿˜æ¬¾æ—¥'] = date_match.group(1)
                elif 'è´¦å•æ—¥' in line:
                    date_match = re.search(r'(\d{4}-\d{2}-\d{2})', line)
                    if date_match:
                        bill_info['è´¦å•æ—¥'] = date_match.group(1)
                elif 'æœ¬æœŸäººæ°‘å¸æ¬ æ¬¾æ€»è®¡' in line:
                    # æŸ¥æ‰¾é‡‘é¢
                    amount_match = re.search(r'(\d+\.\d{2})', line)
                    if amount_match:
                        bill_info['æœ¬æœŸäººæ°‘å¸æ¬ æ¬¾æ€»è®¡'] = amount_match.group(1)
                elif 'æœ¬æœŸæœ€å°è¿˜æ¬¾' in line:
                    amount_match = re.search(r'(\d+\.\d{2})', line)
                    if amount_match:
                        bill_info['æœ¬æœŸæœ€å°è¿˜æ¬¾é¢'] = amount_match.group(1)
            
            # æå–å¡å·ä¿¡æ¯
            elif current_section == 'card_details':
                if re.match(r'\d{4}\s\d{4}\s\s\d{4}', line):
                    bill_info['å¡å·'] = line.strip()
                elif 'æœ¬æœŸåº”è¿˜æ¬¾é¢' in line:
                    amount_match = re.search(r'(\d+\.\d{2})', line)
                    if amount_match and not bill_info['æœ¬æœŸäººæ°‘å¸æ¬ æ¬¾æ€»è®¡']:
                        bill_info['æœ¬æœŸäººæ°‘å¸æ¬ æ¬¾æ€»è®¡'] = amount_match.group(1)
            
            # æå–äº¤æ˜“è®°å½•
            elif current_section == 'transactions':
                # æ£€æµ‹äº¤æ˜“è®°å½•è¡Œï¼ˆåŒ…å«æ—¥æœŸï¼‰
                if re.match(r'\d{4}-\d{2}-\d{2}', line):
                    transaction = {
                        'date': line.strip(),
                        'card_last_four': '',
                        'description': '',
                        'amount': ''
                    }
                    
                    # è¿™æ˜¯ä¸€ä¸ªäº¤æ˜“å¼€å§‹ï¼Œæˆ‘ä»¬éœ€è¦æ”¶é›†åç»­çš„ç›¸å…³è¡Œ
                    transactions.append(transaction)
                elif transactions:
                    # ä¸ºæœ€åä¸€ä¸ªäº¤æ˜“æ·»åŠ ä¿¡æ¯
                    last_transaction = transactions[-1]
                    
                    # æ£€æµ‹å¡å·åå››ä½
                    if re.match(r'^\d{4}$', line):
                        last_transaction['card_last_four'] = line
                    # æ£€æµ‹é‡‘é¢ï¼ˆæ•°å­—æ ¼å¼ï¼‰
                    elif re.match(r'^-?\d+\.?\d*$', line) and not last_transaction['amount']:
                        last_transaction['amount'] = line
                    # æ£€æµ‹äº¤æ˜“æè¿°ï¼ˆåŒ…å«ä¸­æ–‡æˆ–è‹±æ–‡ï¼Œä¸”ä¸æ˜¯çº¯æ•°å­—ï¼‰
                    elif (not re.match(r'^-?\d+\.?\d*$', line) and 
                          not re.match(r'^\d{4}$', line) and 
                          len(line) > 2 and 
                          not last_transaction['description']):
                        # æ¸…ç†æè¿°æ–‡æœ¬
                        clean_desc = line.replace('CHN', '').strip()
                        clean_desc = re.sub(r'[^\w\s\u4e00-\u9fff\-Â·]', '', clean_desc)  # ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€è¿å­—ç¬¦ç­‰
                        last_transaction['description'] = clean_desc
        
        # æ„å»ºæ ¼å¼åŒ–è¾“å‡º
        final_output = []
        
        # è´¦å•æ‘˜è¦
        final_output.append("ğŸ¦ ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡è´¦å•æ‘˜è¦")
        if bill_info['åˆ°æœŸè¿˜æ¬¾æ—¥']:
            final_output.append(f"â° åˆ°æœŸè¿˜æ¬¾æ—¥: {bill_info['åˆ°æœŸè¿˜æ¬¾æ—¥']}")
        if bill_info['è´¦å•æ—¥']:
            final_output.append(f"ğŸ“… è´¦å•æ—¥: {bill_info['è´¦å•æ—¥']}")
        if bill_info['æœ¬æœŸäººæ°‘å¸æ¬ æ¬¾æ€»è®¡']:
            final_output.append(f"ğŸ’° æœ¬æœŸæ¬ æ¬¾æ€»é¢: {bill_info['æœ¬æœŸäººæ°‘å¸æ¬ æ¬¾æ€»è®¡']}å…ƒ")
        if bill_info['æœ¬æœŸæœ€å°è¿˜æ¬¾é¢']:
            final_output.append(f"ğŸ’³ æœ€ä½è¿˜æ¬¾é¢: {bill_info['æœ¬æœŸæœ€å°è¿˜æ¬¾é¢']}å…ƒ")
        if bill_info['å¡å·']:
            final_output.append(f"ğŸ”¢ å¡å·: {bill_info['å¡å·']}")
        
        # äº¤æ˜“æ˜ç»†ï¼ˆå»é‡å’Œæ¸…ç†ï¼‰
        if transactions:
            final_output.append("\n--- äº¤æ˜“æ˜ç»† ---")
            
            # æ¸…ç†äº¤æ˜“è®°å½•ï¼šç§»é™¤ä¸å®Œæ•´çš„è®°å½•ï¼Œåˆå¹¶ç›¸åŒæ—¥æœŸçš„è¿ç»­äº¤æ˜“
            cleaned_transactions = []
            for trans in transactions:
                if trans['description'] and trans['amount']:
                    # å¦‚æœå•†å®¶åç§°å¤ªçŸ­ï¼Œå°è¯•ä»åŸå§‹æ–‡æœ¬ä¸­è·å–æ›´å®Œæ•´çš„æè¿°
                    if len(trans['description']) <= 2:
                        continue
                    cleaned_transactions.append(trans)
            
            # è¾“å‡ºäº¤æ˜“è®°å½•
            for trans in cleaned_transactions:
                emoji = "ğŸ”" if "æ±‰å ¡" in trans['description'] else "ğŸ›’"
                final_output.append(f"ğŸ“… {trans['date']} | ğŸ’³ {trans['card_last_four']} | {emoji} {trans['description']} | ğŸ’° {trans['amount']}å…ƒ")
        
        # å¦‚æœæ²¡æœ‰æå–åˆ°äº¤æ˜“è®°å½•ï¼Œæ·»åŠ æç¤º
        if not transactions or len(cleaned_transactions) == 0:
            final_output.append("\nâš ï¸ äº¤æ˜“æ˜ç»†æå–ä¸å®Œæ•´ï¼Œå»ºè®®æŸ¥çœ‹åŸPDF")
        
        return '\n'.join(final_output)
        
    except Exception as e:
        logger.error(f"ä¸­å›½é“¶è¡Œè´¦å•æ ¼å¼åŒ–å¤±è´¥: {e}")
        return f"è´¦å•æ ¼å¼åŒ–å¼‚å¸¸: {str(e)}"
    
class EmailHandler:
    @staticmethod
    async def get_email_content(msg):
        """ç»Ÿä¸€å†…å®¹è·å–ï¼Œæ·»åŠ ç¿»è¯‘åŠŸèƒ½"""
        try:
            subject = EmailDecoder.decode_email_header(msg.get("Subject", ""))
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸­å›½é“¶è¡Œé‚®ä»¶ä¸”æœ‰PDFé™„ä»¶
            if "ä¸­å›½é“¶è¡Œ" in subject:
                pdf_content = await EmailHandler.extract_pdf_attachment(msg)
                if pdf_content:
                    logger.info("æ£€æµ‹åˆ°ä¸­å›½é“¶è¡ŒPDFé™„ä»¶ï¼Œä¼˜å…ˆå¤„ç†PDFå†…å®¹")
                    return pdf_content
            
            # åŸæœ‰é€»è¾‘ï¼ˆéä¸­å›½é“¶è¡Œé‚®ä»¶æˆ–æ²¡æœ‰PDFé™„ä»¶ï¼‰
            content = ""
            for part in msg.walk():
                if part.get_content_type() == 'text/html':
                    html_bytes = part.get_payload(decode=True)
                    content = ContentProcessor.convert_html_to_text(html_bytes)
                    break
                    
            if not content:
                for part in msg.walk():
                    if part.get_content_type() == 'text/plain':
                        text_bytes = part.get_payload(decode=True)
                        encoding = EmailDecoder.detect_encoding(text_bytes)
                        raw_text = text_bytes.decode(encoding, errors='replace')
                        content = ContentProcessor.clean_text(raw_text)
                        break
                        
            if not content and any(part.get_content_maintype() == 'image' for part in msg.walk()):
                content = "ğŸ“¨ å›¾ç‰‡å†…å®¹ï¼ˆæ–‡æœ¬ä¿¡æ¯å¦‚ä¸‹ï¼‰\n" + "\n".join(
                    f"{k}: {v}" for k,v in msg.items() if k.lower() in ['subject', 'from', 'date']
                )

            # æ£€æµ‹æ˜¯å¦éœ€è¦ç¿»è¯‘
            if content and not is_mainly_chinese(content) and ENABLE_TRANSLATION:
                if DEBUG_MODE:
                    logger.info("æ£€æµ‹åˆ°éä¸­æ–‡å†…å®¹ï¼Œå¼€å§‹ç¿»è¯‘...")
                original_length = len(content)
                translated = await translate_content_async(content)
                if translated and translated != content:
                    if not content.startswith("ä»¥ä¸‹å†…å®¹å·²ç¿»è¯‘:"):
                        content = "ä»¥ä¸‹å†…å®¹å·²ç¿»è¯‘:\n\n" + translated
                    if DEBUG_MODE:
                        logger.info(f"ç¿»è¯‘å®Œæˆï¼ŒåŸå§‹é•¿åº¦: {original_length}, ç¿»è¯‘åé•¿åº¦: {len(translated)}")
            
            return ContentProcessor.normalize_newlines(content or "âš ï¸ æ— æ³•è§£æå†…å®¹")
            
        except Exception as e:
            logger.error(f"å†…å®¹æå–å¤±è´¥: {e}")
            return "âš ï¸ å†…å®¹æå–å¼‚å¸¸"

    @staticmethod
    async def extract_pdf_attachment(msg):
        """æå–PDFé™„ä»¶å†…å®¹ - ä¿®å¤ç‰ˆ"""
        try:
            pdf_attachments = []
            
            for part in msg.walk():
                content_type = part.get_content_type()
                filename = part.get_filename()
                content_disposition = str(part.get("Content-Disposition", ""))
                
                # è§£ç æ–‡ä»¶åï¼ˆå¦‚æœæ˜¯ç¼–ç çš„ï¼‰
                if filename and '=?' in filename:
                    try:
                        filename = EmailDecoder.decode_email_header(filename)
                        logger.info(f"è§£ç åæ–‡ä»¶å: {filename}")
                    except Exception as e:
                        logger.error(f"æ–‡ä»¶åè§£ç å¤±è´¥: {e}")
                
                logger.info(f"æ£€æŸ¥éƒ¨åˆ†: type={content_type}, filename={filename}, disposition={content_disposition}")
                
                # æ£€æµ‹PDFé™„ä»¶ - åŒ…æ‹¬ application/octet-stream ç±»å‹
                is_pdf = (content_type in ["application/pdf", "application/octet-stream"] or 
                         (filename and filename.lower().endswith('.pdf')) or
                         (filename and 'è´¦å•' in filename) or
                         (filename and 'bill' in filename.lower()))
                
                if is_pdf:
                    pdf_data = part.get_payload(decode=True)
                    if pdf_data and len(pdf_data) > 100:
                        actual_filename = filename or "bill.pdf"
                        # éªŒè¯PDFæ–‡ä»¶å¤´
                        if len(pdf_data) >= 4 and pdf_data[:4] == b'%PDF':
                            pdf_attachments.append((actual_filename, pdf_data))
                            logger.info(f"ç¡®è®¤æ‰¾åˆ°PDFæ–‡ä»¶: {actual_filename}, å¤§å°: {len(pdf_data)} å­—èŠ‚")
                        else:
                            logger.info(f"æ‰¾åˆ°ç–‘ä¼¼æ–‡ä»¶ä½†æ–‡ä»¶å¤´ä¸åŒ¹é…: {actual_filename}")
            
            # å¦‚æœæœ‰PDFé™„ä»¶ï¼Œå¤„ç†ç¬¬ä¸€ä¸ª
            if pdf_attachments:
                filename, pdf_data = pdf_attachments[0]
                logger.info(f"å¼€å§‹å¤„ç†PDFé™„ä»¶: {filename}")
                
                # å¼‚æ­¥å¤„ç†PDFå†…å®¹
                loop = asyncio.get_running_loop()
                pdf_text = await loop.run_in_executor(
                    None, 
                    EmailHandler.extract_pdf_text, 
                    pdf_data
                )
                
                if pdf_text:
                    logger.info(f"PDFå†…å®¹æå–æˆåŠŸï¼Œé•¿åº¦: {len(pdf_text)} å­—ç¬¦")
                    
                    # å¦‚æœæ˜¯ä¸­å›½é“¶è¡Œè´¦å•ï¼Œè¿›è¡Œæ ¼å¼åŒ–
                    if "ä¸­å›½é“¶è¡Œ" in filename or "BOC" in filename.upper():
                        logger.info("æ£€æµ‹åˆ°ä¸­å›½é“¶è¡Œè´¦å•ï¼Œè¿›è¡Œæ ¼å¼åŒ–å¤„ç†")
                        formatted_text = format_boc_bill_data(pdf_text)
                        pdf_text = f"ğŸ“„ ä¸­å›½é“¶è¡Œä¿¡ç”¨å¡è´¦å•:\n\n{formatted_text}"
                    
                    # æ£€æµ‹æ˜¯å¦éœ€è¦ç¿»è¯‘
                    if not is_mainly_chinese(pdf_text) and ENABLE_TRANSLATION:
                        translated = await translate_content_async(pdf_text)
                        if translated and translated != pdf_text:
                            pdf_text = f"ğŸ“„ PDFå†…å®¹å·²ç¿»è¯‘ ({filename}):\n\n{translated}"
                        else:
                            pdf_text = f"ğŸ“„ PDFå†…å®¹ ({filename}):\n\n{pdf_text}"
                    else:
                        pdf_text = f"ğŸ“„ PDFå†…å®¹ ({filename}):\n\n{pdf_text}"
                    
                    return ContentProcessor.normalize_newlines(pdf_text)
                else:
                    logger.warning(f"PDFé™„ä»¶æ— æ³•æå–æ–‡æœ¬: {filename}")
                    return f"ğŸ“„ æ‰¾åˆ°PDFé™„ä»¶ä½†æ— æ³•æå–æ–‡æœ¬: {filename}"
            
            logger.info("æœªæ‰¾åˆ°PDFé™„ä»¶")
            return None
            
        except Exception as e:
            logger.error(f"PDFé™„ä»¶å¤„ç†å¤±è´¥: {e}")
            return None

    @staticmethod
    def extract_pdf_text(pdf_data):
        """åŒæ­¥æå–PDFæ–‡æœ¬å†…å®¹ - æ”¹è¿›ç‰ˆ"""
        try:
            # æ‰“å¼€PDFæ–‡æ¡£
            pdf_document = fitz.open(stream=pdf_data, filetype="pdf")
            all_text = []
            
            # æå–æ¯ä¸€é¡µçš„æ–‡æœ¬ï¼Œä½¿ç”¨æ›´å¥½çš„æå–é€‰é¡¹
            for page_num in range(len(pdf_document)):
                page = pdf_document.load_page(page_num)
                
                # ä½¿ç”¨ä¸åŒçš„æ–‡æœ¬æå–é€‰é¡¹
                text_options = [
                    page.get_text(),  # é»˜è®¤æå–
                    page.get_text("text", sort=True),  # æ’åºæ–‡æœ¬
                    page.get_text("words")  # æŒ‰å•è¯æå–
                ]
                
                for text in text_options:
                    if isinstance(text, str) and text.strip():
                        all_text.append(text.strip())
                    elif isinstance(text, list):
                        # å¤„ç†å•è¯åˆ—è¡¨
                        words_text = ' '.join([word[4] for word in text if len(word) > 4])
                        if words_text.strip():
                            all_text.append(words_text.strip())
            
            pdf_document.close()
            
            # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
            combined_text = '\n'.join(all_text)
            
            if combined_text.strip():
                # æ¸…ç†æ–‡æœ¬ä½†ä¿ç•™æ›´å¤šä¿¡æ¯
                cleaned_text = ContentProcessor.clean_text(combined_text)
                # ç§»é™¤è¿‡å¤šçš„ç©ºè¡Œä½†ä¿ç•™æ®µè½ç»“æ„
                cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)
                return cleaned_text
            else:
                logger.warning("PDFæ–‡æ¡£æ²¡æœ‰å¯æå–çš„æ–‡æœ¬å†…å®¹")
                return None
                
        except Exception as e:
            logger.error(f"PDFæ–‡æœ¬æå–å¤±è´¥: {e}")
            return None
        
def clean_bill_data(input_data):
    cleaned_lines = []
    for line in input_data.split('\n'):
        if not line.strip():
            cleaned_lines.append(line)
            continue
            
        parts = [p.strip() for p in line.split('   ') if p.strip()]
        
        # ç§»é™¤ç¬¬äºŒä¸ªæ—¥æœŸï¼ˆç´¢å¼•ä¸º1çš„éƒ¨åˆ†ï¼‰
        if len(parts) > 1:
            parts.pop(1)
        
        # æ£€æŸ¥å¹¶ç§»é™¤é‡å¤çš„è´§å¸é‡‘é¢
        # æŸ¥æ‰¾è´§å¸ä»£ç å‡ºç°çš„ä½ç½®ï¼ˆCNY, USDç­‰ï¼‰
        currency_indices = [i for i, part in enumerate(parts) 
                           if part in ['CNY', 'USD', 'EUR', 'JPY']]  # å¯ä»¥æ·»åŠ æ›´å¤šè´§å¸ä»£ç 
        
        if len(currency_indices) > 1:
            # ä¿ç•™ç¬¬ä¸€ä¸ªè´§å¸å’Œé‡‘é¢ï¼Œç§»é™¤åç»­é‡å¤
            first_currency_index = currency_indices[0]
            currency = parts[first_currency_index]
            # amount_after_first = parts[first_currency_index + 1]  # å¯é€‰ï¼Œæš‚æœªç”¨åˆ°
            
            # ç§»é™¤åç»­æ‰€æœ‰ç›¸åŒè´§å¸å’Œé‡‘é¢
            i = first_currency_index + 2
            while i < len(parts):
                if parts[i] == currency:
                    parts.pop(i)  # ç§»é™¤è´§å¸
                    if i < len(parts):
                        parts.pop(i)  # ç§»é™¤é‡‘é¢
                else:
                    i += 1
        
        cleaned_line = '   '.join(parts)
        cleaned_lines.append(cleaned_line)
    
    return '\n'.join(cleaned_lines)

class MessageFormatter:
    @staticmethod
    async def format_message(sender, subject, content):
        """è¿”å›åˆ†ç¦»çš„headerå’Œbodyï¼Œæ·»åŠ ä¸»é¢˜ç¿»è¯‘"""
        realname, email_address = parseaddr(sender)
        
        clean_realname = re.sub(r'[|]', '', realname).strip()
        clean_email = email_address.strip()
        clean_subject = re.sub(r'\s+', ' ', subject).replace('|', '')
        
        # ä¸»é¢˜ç¿»è¯‘ï¼ˆå¦‚æœæ˜¯éä¸­æ–‡ä¸”å¯ç”¨äº†ç¿»è¯‘ï¼‰
        final_subject = clean_subject
        if clean_subject and not is_mainly_chinese(clean_subject) and ENABLE_TRANSLATION:
            if DEBUG_MODE:
                logger.info("æ£€æµ‹åˆ°éä¸­æ–‡ä¸»é¢˜ï¼Œå¼€å§‹ç¿»è¯‘...")
            translated_subject = await translate_content_async(clean_subject)
            if translated_subject and translated_subject != clean_subject:
                final_subject = f"{clean_subject} ({translated_subject})"
                if DEBUG_MODE:
                    logger.info("ä¸»é¢˜ç¿»è¯‘å®Œæˆ")
        
        # æ„å»ºMarkdownV2æ ¼å¼çš„headeréƒ¨åˆ†
        sender_line = "âœ‰ï¸ "
        if clean_realname:
            sender_line += f"**{clean_realname}**"  # ç”¨æˆ·ååŠ ç²—
        if clean_email:
            if clean_realname:
                sender_line += " "  # åœ¨ç”¨æˆ·åå’Œé‚®ç®±ä¹‹é—´åŠ ç©ºæ ¼
            sender_line += f"`{clean_email}`"  # é‚®ç®±ç­‰å®½
            
        # ä¸»é¢˜å•ç‹¬ä¸€è¡Œï¼ˆä½¿ç”¨å¯èƒ½ç¿»è¯‘åçš„ä¸»é¢˜ï¼‰
        subject_line = f"_{final_subject}_" if final_subject else ""
        
        # ç»„åˆheaderéƒ¨åˆ†
        if sender_line and subject_line:
            header = f"{sender_line}\n{subject_line}\n\n"
        elif sender_line:
            header = f"{sender_line}\n\n"
        elif subject_line:
            header = f"{subject_line}\n\n"
        else:
            header = ""
            
        formatted_content = ContentProcessor.normalize_newlines(content)
        
        return header, formatted_content

    @staticmethod
    def split_content(text, max_length):
        """æ™ºèƒ½åˆ†å‰²ä¼˜åŒ–ï¼ˆè¿”å›åˆ†å‰²åçš„å—åˆ—è¡¨ï¼‰"""
        chunks = []
        current_chunk = []
        current_length = 0

        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]

        for para in paragraphs:
            potential_add = len(para) + (2 if current_chunk else 0)

            if current_length + potential_add > max_length:
                if current_chunk:
                    chunks.append('\n\n'.join(current_chunk))
                    current_chunk = []
                    current_length = 0
                    
                    if len(para) > max_length:
                        start = 0
                        while start < len(para):
                            end = start + max_length
                            chunks.append(para[start:end])
                            start = end
                        continue
                    else:
                        current_chunk.append(para)
                        current_length = len(para)
                else:
                    start = 0
                    while start < len(para):
                        end = start + max_length
                        chunks.append(para[start:end])
                        start = end
            else:
                current_chunk.append(para)
                current_length += potential_add

        if current_chunk:
            chunks.append('\n\n'.join(current_chunk))

        # æœ€ç»ˆé•¿åº¦æ ¡éªŒ
        final_chunks = []
        for chunk in chunks:
            while len(chunk) > max_length:
                final_chunks.append(chunk[:max_length])
                chunk = chunk[max_length:]
            if chunk:
                final_chunks.append(chunk)
        
        return final_chunks

class TelegramBot:
    def __init__(self):
        self.bot = telegram.Bot(TELEGRAM_TOKEN)
        
    async def send_message(self, text):
        """ä½¿ç”¨MarkdownV2æ ¼å¼å‘é€ï¼Œç¡®ä¿åªè½¬ä¹‰ä¸€æ¬¡"""
        try:
            final_text = ContentProcessor.normalize_newlines(text)
            final_text = re.sub(r'^\s*[-]{2,}\s*$', '', final_text, flags=re.MULTILINE)

            # åº”ç”¨Markdownè½¬ä¹‰ï¼ˆåªåœ¨è¿™é‡Œè½¬ä¹‰ä¸€æ¬¡ï¼‰
            escaped_text = escape(final_text)
            
            # è½¬ä¹‰åæ¸…ç†å¤šä½™çš„#å·ï¼Œé˜²æ­¢æ ‡é¢˜è¿‡åº¦è½¬ä¹‰
            cleaned_hashtags = re.sub(r'^(\\)?#+', '', escaped_text, flags=re.MULTILINE)
               
            cleaned_text = ContentProcessor.collapse_empty_lines(cleaned_hashtags)
        # å‘é€æ¶ˆæ¯
            await self.bot.send_message(
                chat_id=TELEGRAM_CHAT_ID,
                text=cleaned_text,
                parse_mode="MarkdownV2",
                disable_web_page_preview=True
            )
        except telegram.error.BadRequest as e:
            logger.error(f"æ¶ˆæ¯è¿‡é•¿é”™è¯¯: {str(e)[:200]}")
        except Exception as e:
            logger.error(f"å‘é€å¤±è´¥: {str(e)[:200]}")

async def main():
    bot = TelegramBot()
    
    try:
        with imaplib.IMAP4_SSL(IMAP_SERVER) as mail:
            mail.login(EMAIL_ADDRESS, EMAIL_PASSWORD)
            mail.select("INBOX")
            
            _, nums = mail.search(None, "UNSEEN")
            if not nums[0]:
                logger.info("æ— æœªè¯»é‚®ä»¶")
                return

            for num in nums[0].split():
                try:
                    _, data = mail.fetch(num, "(RFC822)")
                    msg = email.message_from_bytes(data[0][1])
                    
                    sender = EmailDecoder.decode_email_header(msg.get("From"))
                    subject = EmailDecoder.decode_email_header(msg.get("Subject"))
                    
                    # è®°å½•é‚®ä»¶ä¿¡æ¯
                    logger.info(f"å¤„ç†é‚®ä»¶ - å‘ä»¶äºº: {sender}, ä¸»é¢˜: {subject}")
                    
                    # è°ƒè¯•ï¼šåˆ†æé‚®ä»¶ç»“æ„
                    if "ä¸­å›½é“¶è¡Œ" in subject and DEBUG_MODE:
                        logger.info("=== é‚®ä»¶ç»“æ„åˆ†æ ===")
                        for part in msg.walk():
                            content_type = part.get_content_type()
                            filename = part.get_filename()
                            content_disposition = str(part.get("Content-Disposition", ""))
                            logger.info(f"éƒ¨åˆ†: {content_type}, æ–‡ä»¶å: {filename}, å¤„ç½®: {content_disposition}")
                        logger.info("=== åˆ†æç»“æŸ ===")
                    
                    content = await EmailHandler.get_email_content(msg)

                    header, body = await MessageFormatter.format_message(sender, subject, content)
                    header_len = len(header)
                    max_body_len = MAX_MESSAGE_LENGTH - header_len

                    # ------- è¿™é‡Œé›†æˆè´¦å•æ¸…æ´—é€»è¾‘ ---------
                    if "å»ºè®¾é“¶è¡Œä¿¡ç”¨å¡" in subject:
                        body = clean_bill_data(body)
                    # --------------------------------------

                    # å¤„ç†headerè¿‡é•¿çš„æƒ…å†µ
                    if max_body_len <= 0:
                        header = header[:MAX_MESSAGE_LENGTH-4] + "..."
                        header_len = len(header)
                        max_body_len = MAX_MESSAGE_LENGTH - header_len

                    # ç¬¬ä¸€æ­¥ï¼šåˆ†å‰²å¸¦headerçš„é¦–ä¸ªæ¶ˆæ¯
                    first_part_chunks = MessageFormatter.split_content(body, max_body_len)
                    
                    # å‘é€é¦–ä¸ªæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰å†…å®¹ï¼‰
                    if first_part_chunks:
                        first_chunk = first_part_chunks[0]
                        await bot.send_message(header + first_chunk)
                        
                        # ç¬¬äºŒæ­¥ï¼šå¤„ç†å‰©ä½™å†…å®¹ï¼ˆä¸å¸¦headerï¼‰
                        remaining_body = '\n\n'.join(
                            para 
                            for chunk in first_part_chunks[1:] 
                            for para in chunk.split('\n\n')
                        )
                    else:
                        remaining_body = body

                    # ç¬¬ä¸‰æ­¥ï¼šåˆ†å‰²å‰©ä½™å†…å®¹ï¼ˆä½¿ç”¨å®Œæ•´é•¿åº¦é™åˆ¶ï¼‰
                    subsequent_chunks = MessageFormatter.split_content(remaining_body, MAX_MESSAGE_LENGTH)
                    
                    # å‘é€åç»­æ¶ˆæ¯
                    for chunk in subsequent_chunks:
                        await bot.send_message(chunk)
                        
                    mail.store(num, "+FLAGS", "\\Seen")
                    
                except Exception as e:
                    logger.error(f"å¤„ç†å¼‚å¸¸: {str(e)[:200]}")
                    continue

    except Exception as e:
        logger.error(f"è¿æ¥å¼‚å¸¸: {str(e)[:200]}")

if __name__ == "__main__":
    asyncio.run(main())